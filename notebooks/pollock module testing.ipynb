{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '/tf/pollock')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/anndata/_core/anndata.py:21: FutureWarning: pandas.core.index is deprecated and will be removed in a future version.  The public classes are available in the top-level namespace.\n",
      "  from pandas.core.index import RangeIndex\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import os\n",
    "import random\n",
    "from collections import Counter\n",
    "from importlib import reload\n",
    "import time\n",
    "\n",
    "import anndata\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pollock\n",
    "from pollock import PollockDataset, PollockModel, load_from_directory\n",
    "# import pollock.models.analysis as pollock_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "tf.keras.backend.clear_session()  # For easy reset of notebook state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = '/data/single_cell_classification'\n",
    "MODEL_DIR = '/models'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_name = 'br'\n",
    "\n",
    "expression_fp = os.path.join(DATA_DIR, 'tumor', 'BR', 'raw', 'houxiang_brca',\n",
    "                            'breast_counts_matrix.tsv')\n",
    "label_fp = os.path.join(DATA_DIR, 'tumor', 'BR', 'raw', 'houxiang_brca',\n",
    "                            'breast_metadata.tsv')\n",
    "\n",
    "training_image_dir = os.path.join(MODEL_DIR, 'scratch', run_name)\n",
    "model_save_dir = os.path.join(MODEL_DIR, run_name)\n",
    "\n",
    "sample_column = 'Genes'\n",
    "sep='\\t'\n",
    "cell_type_key = 'cell_type'\n",
    "\n",
    "n_per_cell_type = 5000\n",
    "epochs = 5\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expression_df = pd.read_hdf(expression_fp.replace('.tsv', '.h5'), 'df')\n",
    "expression_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_df = pd.read_csv(\n",
    "    label_fp,\n",
    "    sep=sep\n",
    "    )\n",
    "label_df = label_df.set_index('cell_id')\n",
    "label_df = label_df.loc[expression_df.index]\n",
    "label_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = anndata.AnnData(X=expression_df.values, obs=label_df)\n",
    "adata.obs.index = expression_df.index\n",
    "adata.var.index = expression_df.columns\n",
    "adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = Counter(adata.obs[cell_type_key])\n",
    "counts.most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## get rid of unknowns\n",
    "adata = adata[adata.obs[cell_type_key]!='Unknown']\n",
    "adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def __init__(self, adata, cell_type_key='ClusterName', n_per_cell_type=500,\n",
    "# ¦   ¦   batch_size=64, dataset_type='training', min_genes=200, min_cells=3, mito_threshold=.2,\n",
    "# ¦   ¦   max_n_genes=None, log=True, cpm=True, min_disp=.2, standard_scaler=None,\n",
    "# ¦   ¦   range_scaler=None, cell_type_encoder=None, genes=None, cell_types=None):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pds = PollockDataset(adata.copy(), cell_type_key=cell_type_key, n_per_cell_type=1000, batch_size=128,\n",
    "                    dataset_type='training', min_genes=200, min_cells=3, mito_threshold=None,\n",
    "                    max_n_genes=None, log=True, cpm=False, min_disp=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(pds.val_adata.obs[cell_type_key]).most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class BVAE(tf.keras.Model):\n",
    "#   def __init__(self, latent_dim, input_size):\n",
    "#     super(BVAE, self).__init__()\n",
    "#     self.latent_dim = latent_dim\n",
    "#     self.input_size = input_size\n",
    "#     self.inference_net = tf.keras.Sequential(\n",
    "#       [\n",
    "#           tf.keras.layers.InputLayer(input_shape=(input_size,)),\n",
    "#           tf.keras.layers.Dense(800, activation='relu'),\n",
    "#           tf.keras.layers.Dropout(.2),\n",
    "#           tf.keras.layers.Dense(800, activation='relu'),\n",
    "#           tf.keras.layers.Dropout(.2),\n",
    "#           tf.keras.layers.Dense(latent_dim + latent_dim),\n",
    "#       ]\n",
    "#     )\n",
    "\n",
    "#     self.generative_net = tf.keras.Sequential(\n",
    "#         [\n",
    "#           tf.keras.layers.InputLayer(input_shape=(latent_dim,)),\n",
    "#           tf.keras.layers.Dense(800, activation='relu'),\n",
    "#           tf.keras.layers.Dropout(.2),\n",
    "#           tf.keras.layers.Dense(800, activation='relu'),\n",
    "#           tf.keras.layers.Dropout(.2),\n",
    "#           tf.keras.layers.Dense(input_size),\n",
    "#         ]\n",
    "#     )\n",
    "\n",
    "#   @tf.function\n",
    "#   def sample(self, eps=None):\n",
    "#     if eps is None:\n",
    "#       eps = tf.random.normal(shape=(100, self.latent_dim))\n",
    "#     return self.decode(eps, apply_sigmoid=True)\n",
    "\n",
    "#   def encode(self, x):\n",
    "#     mean, logvar = tf.split(self.inference_net(x), num_or_size_splits=2, axis=1)\n",
    "#     return mean, logvar\n",
    "\n",
    "#   def reparameterize(self, mean, logvar):\n",
    "#     eps = tf.random.normal(shape=mean.shape)\n",
    "#     return eps * tf.exp(logvar * .5) + mean\n",
    "\n",
    "#   def decode(self, z, apply_sigmoid=False):\n",
    "#     logits = self.generative_net(z)\n",
    "#     if apply_sigmoid:\n",
    "#       probs = tf.sigmoid(logits)\n",
    "#       return probs\n",
    "\n",
    "#     return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "\n",
    "# def log_normal_pdf(sample, mean, logvar, raxis=1):\n",
    "#   log2pi = tf.math.log(2. * np.pi)\n",
    "#   return tf.reduce_sum(\n",
    "#       -.5 * ((sample - mean) ** 2. * tf.exp(-logvar) + logvar + log2pi),\n",
    "#       axis=raxis)\n",
    "\n",
    "# @tf.function\n",
    "# def compute_loss(model, x, alpha=0.00005):\n",
    "#   mean, logvar = model.encode(x)\n",
    "#   z = model.reparameterize(mean, logvar)\n",
    "#   x_logit = model.decode(z)\n",
    "\n",
    "#   kl_loss = .5 * tf.reduce_sum(tf.exp(logvar) + tf.square(mean) - 1. - logvar, axis=1)\n",
    "#   reconstruction_loss = .5 * tf.reduce_sum(tf.square((x - x_logit)), axis=1)\n",
    "\n",
    "#   overall_loss = tf.reduce_mean(reconstruction_loss + alpha * kl_loss)\n",
    "#   return overall_loss\n",
    "\n",
    "# @tf.function\n",
    "# def compute_apply_gradients(model, x, optimizer, alpha=.00005):\n",
    "#   with tf.GradientTape() as tape:\n",
    "#     loss = compute_loss(model, x, alpha=alpha)\n",
    "#   gradients = tape.gradient(loss, model.trainable_variables)\n",
    "#   optimizer.apply_gradients(zip(gradients, model.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# epochs = 50\n",
    "# latent_dim = 100\n",
    "# alpha = 0.1\n",
    "# # num_examples_to_generate = 16\n",
    "\n",
    "# # keeping the random vector constant for generation (prediction) so\n",
    "# # it will be easier to see the improvement.\n",
    "# # random_vector_for_generation = tf.random.normal(\n",
    "# #     shape=[num_examples_to_generate, latent_dim])\n",
    "# model = BVAE(latent_dim, pds.val_adata.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # generate_and_save_images(model, 0, random_vector_for_generation)\n",
    "\n",
    "# for epoch in range(1, epochs + 1):\n",
    "#   start_time = time.time()\n",
    "#   for train_x in pds.train_ds:\n",
    "#     compute_apply_gradients(model, train_x, optimizer, alpha=alpha)\n",
    "#   end_time = time.time()\n",
    "\n",
    "#   if epoch % 1 == 0:\n",
    "#     loss = tf.keras.metrics.Mean()\n",
    "#     for test_x in pds.val_ds:\n",
    "#       loss(compute_loss(model, test_x, alpha=alpha))\n",
    "#     print(f'epoch: {epoch}, val loss: {loss.result()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean, logvar = model.encode(pds.train_adata.X)\n",
    "# train_embeddings = model.reparameterize(mean, logvar).numpy()\n",
    "\n",
    "# mean, logvar = model.encode(pds.val_adata.X[:10000])\n",
    "# val_embeddings = model.reparameterize(mean, logvar).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import OrdinalEncoder\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# encoder = OrdinalEncoder()\n",
    "# y_train = encoder.fit_transform(np.asarray(pds.train_adata.obs[cell_type_key]).reshape(-1, 1)).flatten()\n",
    "# y_val = encoder.transform(np.asarray(pds.val_adata.obs[cell_type_key][:10000]).reshape(-1, 1)).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# clf.fit(train_embeddings, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf.score(train_embeddings, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf.score(val_embeddings, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm = PollockModel(pds.cell_types, pds.train_adata.shape[1], alpha=.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.fit(pds, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.save(pds, os.path.join(MODEL_DIR, 'testing'), )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.summary['training']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.summary['validation']['metrics']['accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.summary['training']['metrics']['accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_pds, l_pm = load_from_directory(adata, os.path.join(MODEL_DIR, 'testing'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = l_pm.predict_pollock_dataset(l_pds, labels=True, )\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
