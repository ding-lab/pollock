{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "import os\n",
    "import re\n",
    "import random\n",
    "import subprocess\n",
    "\n",
    "import anndata\n",
    "import scanpy as sc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import mgitools.os_helpers as os_helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install git+https://github.com/estorrs/mgitools\n",
    "# !pip install tensorflow==2.1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -e /home/estorrs/pollock/\n",
    "import pollock\n",
    "from pollock.models.model import PollockDataset, PollockModel, load_from_directory, predict_from_anndata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !conda install -y scanpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install git+https://github.com/estorrs/mgitools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "CELL_TYPE_KEY = 'cell_type'\n",
    "N_PER_CELL_TYPE = 200\n",
    "DATA_DIR = '/home/estorrs/pollock/benchmarking/data/10232020_harmonized/teir_1/'\n",
    "RESULTS_DIR = '/home/estorrs/pollock/benchmarking/results/10272020_teir1'\n",
    "SANDBOX_DIR = '/home/estorrs/pollock/benchmarking/sandbox'\n",
    "\n",
    "POLLOCK_MODELS_DIR = '/home/estorrs/pollock/benchmarking/results/10272020_teir1_modules'\n",
    "\n",
    "Path(RESULTS_DIR).mkdir(parents=True, exist_ok=True)\n",
    "Path(POLLOCK_MODELS_DIR).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "##### create training and validation datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "only run if you haven't created these datasets yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def cap_list(ls, n=100, split=.8, oversample=True):\n",
    "    \"\"\"\n",
    "    Grabs items from a pool.\n",
    "    \n",
    "    if split * pool size is greater than n, then just randomly sample 80% of the pool\n",
    "    otherwise sample 80% of the pool, then oversample so you end up with a final size of n\n",
    "    \"\"\"\n",
    "    cap = int(len(ls) * split)\n",
    "    if cap > n:\n",
    "        return random.sample(ls, n)\n",
    "\n",
    "    if oversample:\n",
    "        pool = random.sample(ls, cap)\n",
    "        ## oversample to\n",
    "        return random.choices(pool, k=n)\n",
    "\n",
    "    return random.sample(ls, cap)\n",
    "\n",
    "def balancedish_training_generator(adata, cell_type_key, n_per_cell_type, oversample=True, split=.8):\n",
    "    \"\"\"\n",
    "    Return balanced train and validation sets\n",
    "    \"\"\"\n",
    "    cell_type_to_idxs = {}\n",
    "    for cell_id, cell_type in zip(adata.obs.index, adata.obs[cell_type_key]):\n",
    "        if cell_type not in cell_type_to_idxs:\n",
    "            cell_type_to_idxs[cell_type] = [cell_id]\n",
    "        else:\n",
    "            cell_type_to_idxs[cell_type].append(cell_id)\n",
    "\n",
    "    cell_type_to_idxs = {k:cap_list(ls, n_per_cell_type, oversample=oversample, split=split)\n",
    "                         for k, ls in cell_type_to_idxs.items()}\n",
    "\n",
    "    train_ids = np.asarray([x for ls in cell_type_to_idxs.values() for x in ls])\n",
    "    train_idxs = np.arange(adata.shape[0])[np.isin(np.asarray(adata.obs.index), train_ids)]\n",
    "    val_idxs = np.delete(np.arange(adata.shape[0]), train_idxs)\n",
    "\n",
    "    train_adata = adata[train_idxs, :]\n",
    "    val_adata = adata[val_idxs, :]\n",
    "\n",
    "    return train_adata, val_adata\n",
    "\n",
    "# def create_train_val_datasets(adata, cell_type_key, oversample=True):\n",
    "#     counts = Counter(adata.obs[cell_type_key])\n",
    "#     min_count = counts.most_common()[-1][1]\n",
    "#     n_per_cell_type = max(min_count, )\n",
    "#     train_adata, val_adata = balancedish_training_generator(adata, cell_type_key,\n",
    "#                                                             n_per_cell_type, oversample=oversample)\n",
    "#     return train_adata, val_adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fps = sorted(os_helpers.listfiles(DATA_DIR, regex='.h5ad$'))\n",
    "fp_map = {fp.split('/')[-2]:{} for fp in fps}\n",
    "for fp in fps:\n",
    "    if '/_train.h5ad' not in fp and '/_val.h5ad' not in fp:\n",
    "        dtype = fp.split('/')[-2]\n",
    "        disease = fp.split('/')[-1].replace('.h5ad', '')\n",
    "        fp_map[dtype][disease] = fp\n",
    "fp_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for dtype, d in fp_map.items():\n",
    "    for disease, fp in d.items():\n",
    "        print(dtype, disease)\n",
    "        adata = sc.read_h5ad(fp)\n",
    "        # check for cell type key\n",
    "        if CELL_TYPE_KEY not in adata.obs: raise RuntimeError(f'{CELL_TYPE_KEY} not in {fp}')\n",
    "        \n",
    "        train_adata, val_adata = balancedish_training_generator(adata, CELL_TYPE_KEY, N_PER_CELL_TYPE)\n",
    "        # resample validation data to make dataset smaller while keeping rare cell types\n",
    "        val_adata, _ = balancedish_training_generator(val_adata, CELL_TYPE_KEY, 1000, oversample=False,\n",
    "                                                     split=1.)\n",
    "        train_adata.write_h5ad(fp.replace('.h5ad', '_train.h5ad'))\n",
    "        val_adata.write_h5ad(fp.replace('.h5ad', '_val.h5ad'))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### load in training and validation datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scRNAseq brca\n",
      "scRNAseq cesc\n",
      "scRNAseq hnscc\n",
      "scRNAseq melanoma\n",
      "scRNAseq pbmc\n",
      "scRNAseq pdac\n",
      "snATACseq brca\n",
      "snATACseq ccrcc\n",
      "snATACseq gbm\n",
      "snRNAseq brca\n",
      "snRNAseq ccrcc\n",
      "snRNAseq gbm\n"
     ]
    }
   ],
   "source": [
    "fps = sorted(os_helpers.listfiles(DATA_DIR, regex='.h5ad$'))\n",
    "adata_map = {fp.split('/')[-2]:{} for fp in fps}\n",
    "for fp in fps:\n",
    "    dtype = fp.split('/')[-2]\n",
    "    disease = re.sub(r'^(.*)((_train)|(_val)).h5ad$', r'\\1', fp.split('/')[-1])\n",
    "    if disease not in adata_map[dtype] and '.h5ad' not in disease: adata_map[dtype][disease] = {}\n",
    "    if 'train.h5ad' in fp:\n",
    "        adata_map[dtype][disease]['train'] = fp\n",
    "    if 'val.h5ad' in fp:\n",
    "        adata_map[dtype][disease]['val'] = fp\n",
    "for dtype, d in adata_map.items():\n",
    "    for disease, m in d.items():\n",
    "        print(dtype, disease)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': '/home/estorrs/pollock/benchmarking/data/10232020_harmonized/teir_1/snATACseq/ccrcc_train.h5ad',\n",
       " 'val': '/home/estorrs/pollock/benchmarking/data/10232020_harmonized/teir_1/snATACseq/ccrcc_val.h5ad'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata_map['snATACseq'].pop('ccrcc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### run workflows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_workflow_for_datasets(adata_map, workflow, workflow_identifier, output_dir):\n",
    "    for dtype, d in adata_map.items():\n",
    "#         if dtype != 'snATACseq':\n",
    "        for disease, m in d.items():\n",
    "            # make dir if doesnt exist yet\n",
    "            directory = os.path.join(output_dir, dtype, disease)\n",
    "            Path(directory).mkdir(parents=True, exist_ok=True)\n",
    "            train, val = sc.read_h5ad(m['train']), sc.read_h5ad(m['val'])\n",
    "\n",
    "            print(dtype, disease, train.shape, val.shape)\n",
    "            run_workflow(workflow, workflow_identifier,\n",
    "                train, val, directory)\n",
    "\n",
    "def run_workflow(workflow, workflow_identifier, train, val, output_dir):\n",
    "    \"\"\"\n",
    "    Run the workflow defined by the workflow function.\n",
    "    \n",
    "    workflow function takes a train adata and a val adata as inputs,\n",
    "    and returns dataframe with cell_id, groundtruth, predicted, and probability columns\n",
    "    \"\"\"\n",
    "    # if it is pollock it needs to know where to save the module\n",
    "    if workflow_identifier == 'pollock':\n",
    "        df = workflow(train, val, CELL_TYPE_KEY, os.path.join(output_dir, f'{workflow_identifier}_module'))\n",
    "    else:\n",
    "        df = workflow(train, val, CELL_TYPE_KEY)\n",
    "    df.to_csv(os.path.join(output_dir, f'{workflow_identifier}.tsv'), sep='\\t', index=False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### pollock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_pollock_workflow(train, val, cell_type_key, module_fp):\n",
    "    train.obs['is_validation'] = [False] * train.shape[0]\n",
    "    val.obs['is_validation'] = [True] * val.shape[0]\n",
    "    combined = train.concatenate(val)\n",
    "    \n",
    "    pds = PollockDataset(combined.copy(), cell_type_key=cell_type_key,\n",
    "                     dataset_type='training', validation_key='is_validation')\n",
    "    \n",
    "    pm = PollockModel(pds.cell_types, pds.train_adata.shape[1], alpha=.0001, latent_dim=25)\n",
    "    \n",
    "    pm.fit(pds, epochs=20)\n",
    "    \n",
    "    pm.save(pds, module_fp)\n",
    "\n",
    "    preds = predict_from_anndata(val.copy(), module_fp, adata_batch_size=10000)\n",
    "    \n",
    "    df = pd.DataFrame.from_dict({\n",
    "        'cell_id': preds.index.to_list(),\n",
    "        'groundtruth': val.obs.loc[preds.index][cell_type_key].to_list(),\n",
    "        'predicted': preds['predicted_cell_type'],\n",
    "        'probability': preds['cell_type_probability']\n",
    "    })\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "run_workflow_for_datasets(adata_map, run_pollock_workflow, 'pollock', RESULTS_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "###### testing stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train, val = sc.read_h5ad(adata_map['snRNAseq']['brca']['train']), sc.read_h5ad(adata_map['scRNAseq']['brca']['val'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "module_dir = os.path.join(SANDBOX_DIR, 'temp_module')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train.obs['is_validation'] = [False] * train.shape[0]\n",
    "val.obs['is_validation'] = [True] * val.shape[0]\n",
    "combined = train.concatenate(val)\n",
    "combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# pds = PollockDataset(train, cell_type_key=CELL_TYPE_KEY,\n",
    "#                      dataset_type='training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pds = PollockDataset(combined, cell_type_key=CELL_TYPE_KEY,\n",
    "                     dataset_type='training', validation_key='is_validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pm = PollockModel(pds.cell_types, pds.train_adata.shape[1], alpha=.0001, latent_dim=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pm.fit(pds, epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pm.save(pds, module_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "preds = predict_from_anndata(val.copy(),\n",
    "        '/home/estorrs/pollock/benchmarking/sandbox/temp_module', adata_batch_size=10000)\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict({\n",
    "    'cell_id': preds.index.to_list(),\n",
    "    'groundtruth': val.obs.loc[preds.index][CELL_TYPE_KEY].to_list(),\n",
    "    'predicted': preds['predicted_cell_type'],\n",
    "    'probability': preds['cell_type_probability']\n",
    "})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### scanpy ingest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ingest_preprocess(adata):\n",
    "    adata.var['mt'] = adata.var_names.str.startswith('MT-')\n",
    "    sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True)\n",
    "    sc.pp.normalize_total(adata, target_sum=1e4)\n",
    "    sc.pp.log1p(adata)\n",
    "    sc.pp.highly_variable_genes(adata, flavor=\"seurat\", n_top_genes=2500)\n",
    "    adata.raw = adata\n",
    "    adata = adata[:, adata.var.highly_variable]\n",
    "    sc.pp.regress_out(adata, ['total_counts', 'pct_counts_mt'])\n",
    "    sc.pp.scale(adata)\n",
    "    \n",
    "    return adata\n",
    "\n",
    "def run_scanpy_workflow(train, val, cell_type_key):\n",
    "    var_names = train.var_names.intersection(val.var_names)\n",
    "    train = train[:, var_names]\n",
    "    val = val[:, var_names]\n",
    "    \n",
    "    groundtruth = val.obs[cell_type_key].to_list()\n",
    "\n",
    "    sc.pp.pca(train)\n",
    "    sc.pp.neighbors(train)\n",
    "    sc.tl.umap(train)\n",
    "    \n",
    "    sc.tl.ingest(val, train, obs=cell_type_key)\n",
    "    \n",
    "    df = pd.DataFrame.from_dict({\n",
    "        'cell_id': val.obs.index.to_list(),\n",
    "        'groundtruth': groundtruth,\n",
    "        'prediction': val.obs[cell_type_key].to_list(),\n",
    "        'probability': [np.nan] * val.shape[0]\n",
    "    })\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_workflow_for_datasets(adata_map, run_scanpy_workflow, 'scanpy_ingest', RESULTS_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "###### testing stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train, val = adata_map['scRNAseq']['pbmc']['train'].copy(), adata_map['scRNAseq']['pbmc']['val'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train, val = ingest_preprocess(train), ingest_preprocess(val)\n",
    "\n",
    "var_names = train.var_names.intersection(val.var_names)\n",
    "train = train[:, var_names]\n",
    "val = val[:, var_names]\n",
    "\n",
    "sc.pp.pca(train)\n",
    "sc.pp.neighbors(train)\n",
    "sc.tl.umap(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sc.pl.umap(train, color='cell_type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sc.tl.ingest(val, train, obs=CELL_TYPE_KEY)\n",
    "val.uns[f'{CELL_TYPE_KEY}_colors'] = train.uns[f'{CELL_TYPE_KEY}_colors']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sc.pl.umap(val, color=[CELL_TYPE_KEY], wspace=0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "val.obs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ACTINN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_actinn_workflow(train, val, cell_type_key):\n",
    "    X = train.X.toarray() if 'sparse' in str(type(train.X)) else train.X\n",
    "    train_counts_df = pd.DataFrame(data=X.transpose(), index=train.var.index.to_list(),\n",
    "                        columns=train.obs.index.to_list())\n",
    "    X = val.X.toarray() if 'sparse' in str(type(val.X)) else val.X\n",
    "    val_counts_df = pd.DataFrame(data=X.transpose(), index=val.var.index.to_list(),\n",
    "                        columns=val.obs.index.to_list())\n",
    "    \n",
    "    train_counts_fp = os.path.join(SANDBOX_DIR, 'train_counts.txt')\n",
    "    val_counts_fp = os.path.join(SANDBOX_DIR, 'val_counts.txt')\n",
    "    train_counts_df.to_csv(train_counts_fp, sep='\\t')\n",
    "    val_counts_df.to_csv(val_counts_fp, sep='\\t')\n",
    "    \n",
    "    train_h5_fp = os.path.join(SANDBOX_DIR, 'train.h5')\n",
    "    train_annotations_fp = os.path.join(SANDBOX_DIR, 'train_annotations.txt')\n",
    "    val_h5_fp = os.path.join(SANDBOX_DIR, 'val.h5')\n",
    "\n",
    "    train.obs[[CELL_TYPE_KEY]].to_csv(train_annotations_fp, sep='\\t', index=True, header=False)\n",
    "\n",
    "    subprocess.check_output(('python', ACTINN_FORMAT, '-i', train_counts_fp,\n",
    "                            '-o', train_h5_fp.replace('.h5', ''), '-f', 'txt'))\n",
    "    subprocess.check_output(('python', ACTINN_FORMAT, '-i', val_counts_fp,\n",
    "                            '-o', val_h5_fp.replace('.h5', ''), '-f', 'txt'))\n",
    "    # dont use probablity argument or it breaks\n",
    "    subprocess.check_output(('python', ACTINN_PREDICT, '-trs', train_h5_fp,\n",
    "                            '-trl', train_annotations_fp, '-ts', val_h5_fp))\n",
    "    \n",
    "    prediction_df = pd.read_csv('predicted_label.txt', sep='\\t')\n",
    "    \n",
    "    df = pd.DataFrame.from_dict({\n",
    "        'cell_id': prediction_df['cellname'].to_list(),\n",
    "        'prediction': prediction_df['celltype'].to_list(),\n",
    "        'probability': [np.nan] * prediction_df.shape[0]\n",
    "    })\n",
    "    \n",
    "    df = pd.merge(df, val.obs, left_on='cell_id', right_index=True)\n",
    "    df = df[['cell_id', 'cell_type', 'prediction', 'probability']]\n",
    "    df.columns = ['cell_id', 'groundtruth', 'prediction', 'probability']\n",
    "    \n",
    "    return df\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACTINN_FORMAT = '/home/estorrs/ACTINN/actinn_format.py'\n",
    "ACTINN_PREDICT = '/home/estorrs/ACTINN/actinn_predict.py'\n",
    "\n",
    "run_workflow_for_datasets(adata_map, run_actinn_workflow, 'actinn', RESULTS_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "###### testing stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train, val = adata_map['scRNAseq']['pbmc']['train'].copy(), adata_map['scRNAseq']['pbmc']['val'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# train.obs['dataset'] = ['train'] * train.shape[0]\n",
    "# val.obs['dataset'] = ['val'] * val.shape[0]\n",
    "# combined = train.concatenate(val)\n",
    "# combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_counts_df = pd.DataFrame(data=train.X.transpose().toarray(), index=train.var.index.to_list(),\n",
    "                        columns=train.obs.index.to_list())\n",
    "val_counts_df = pd.DataFrame(data=val.X.transpose().toarray(), index=val.var.index.to_list(),\n",
    "                        columns=val.obs.index.to_list())\n",
    "train_counts_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_counts_fp = os.path.join(SANDBOX_DIR, 'train_counts.txt')\n",
    "val_counts_fp = os.path.join(SANDBOX_DIR, 'val_counts.txt')\n",
    "train_counts_df.to_csv(train_counts_fp, sep='\\t')\n",
    "val_counts_df.to_csv(val_counts_fp, sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "python actinn_format.py -i input_file -o output_prefix -f format\n",
    "\n",
    "python actinn_format.py -i ./test_data/train_set.txt.gz -o train_set -f txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_h5_fp = os.path.join(SANDBOX_DIR, 'train.h5')\n",
    "train_annotations_fp = os.path.join(SANDBOX_DIR, 'train_annotations.txt')\n",
    "val_h5_fp = os.path.join(SANDBOX_DIR, 'val.h5')\n",
    "\n",
    "train.obs[[CELL_TYPE_KEY]].to_csv(train_annotations_fp, sep='\\t', index=True, header=False)\n",
    "\n",
    "subprocess.check_output(('python', '/home/estorrs/ACTINN/actinn_format.py', '-i', train_counts_fp,\n",
    "                        '-o', train_h5_fp.replace('.h5', ''), '-f', 'txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "subprocess.check_output(('python', '/home/estorrs/ACTINN/actinn_format.py', '-i', val_counts_fp,\n",
    "                        '-o', val_h5_fp.replace('.h5', ''), '-f', 'txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train.obs[[CELL_TYPE_KEY]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "python actinn_predict.py -trs training_set -trl training_label -ts test_set -lr learning_rat -ne num_epoch -ms minibatch_size -pc print_cost -op output_probability\n",
    "\n",
    "\n",
    "-trs Path to the training set, must be HDF5 format with key \"dge\".\n",
    "\n",
    "-trl Path to the training label (the cell types for the training set), must be tab separated text file with no column and row names.\n",
    "\n",
    "-ts Path to test sets, must be HDF5 format with key \"dge\".\n",
    "\n",
    "-lr Learning rate (default: 0.0001). We can increase the learning rate if the cost drops too slow, or decrease the learning rate if the cost drops super fast in the beginning and starts to fluctuate in later epochs.\n",
    "\n",
    "-ne Number of epochs (default: 50). The number of epochs can be determined by looking at the cost after each epoch. If the cost starts to decrease very slowly after ceartain epoch, then the \"ne\" parameter should be set to that epoch number.\n",
    "\n",
    "-ms Minibatch size (default: 128). This parameter can be set larger when training a large dataset.\n",
    "\n",
    "-pc Print cost (default: True). Whether to print cost after each 5 epochs.\n",
    "\n",
    "-op Output probabilities for each cell being the cell types in the training data (default: False).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "subprocess.check_output(('python', '/home/estorrs/ACTINN/actinn_predict.py', '-trs', train_h5_fp,\n",
    "                        '-trl', train_annotations_fp, '-ts', val_h5_fp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "' '.join(('python', '/home/estorrs/ACTINN/actinn_predict.py', '-trs', train_h5_fp,\n",
    "                        '-trl', train_annotations_fp, '-ts', val_h5_fp,\n",
    "                        '-op', 'True'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "prediction_df = pd.read_csv('predicted_label.txt', sep='\\t')\n",
    "prediction_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict({\n",
    "        'cell_id': prediction_df['cellname'].to_list(),\n",
    "        'prediction': prediction_df['celltype'].to_list(),\n",
    "        'probability': [np.nan] * val.shape[0]\n",
    "    })\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "val.obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df = pd.merge(df, val.obs, left_on='cell_id', right_index=True)\n",
    "df = df[['cell_id', 'cell_type', 'prediction', 'probability']]\n",
    "df.columns = ['cell_id', 'groundtruth', 'prediction', 'probability']\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Seurat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_seurat_transfer(train, val, cell_type_key):\n",
    "    # save the input data for the seurat script\n",
    "    train_counts_fp, val_counts_fp = (os.path.join(SANDBOX_DIR, 'train_counts.txt'),\n",
    "                                        os.path.join(SANDBOX_DIR, 'val_counts.txt'))\n",
    "    train_annotations_fp, val_annotations_fp = (os.path.join(SANDBOX_DIR, 'train_annotations.txt'),\n",
    "                                                os.path.join(SANDBOX_DIR, 'val_annotations.txt'))\n",
    "\n",
    "    ## prepare train and val count matrices\n",
    "    X = train.X.toarray() if 'sparse' in str(type(train.X)) else train.X\n",
    "    train_counts = pd.DataFrame(data=X.transpose().astype(np.int32), index=train.var.index,\n",
    "                                columns=train.obs.index)\n",
    "    train_counts.index.name = ''\n",
    "    # for some reason SCTransform fails if the integer values are too high, so capping them here\n",
    "    cap = pow(2, 14)\n",
    "    train_counts.values[train_counts.values>cap] = cap\n",
    "    train_counts.to_csv(train_counts_fp, sep='\\t', header=True, index=True)\n",
    "    \n",
    "    X = val.X.toarray() if 'sparse' in str(type(val.X)) else val.X\n",
    "    val_counts = pd.DataFrame(data=X.transpose().astype(np.int32), index=val.var.index,\n",
    "                                columns=val.obs.index)\n",
    "    val_counts.index.name = ''\n",
    "    val_counts.values[val_counts.values>cap] = cap\n",
    "    val_counts.to_csv(val_counts_fp, sep='\\t', header=True, index=True)\n",
    "\n",
    "    train.obs[[CELL_TYPE_KEY]].to_csv(train_annotations_fp, sep='\\t', header=False, index=False)\n",
    "    val.obs[[CELL_TYPE_KEY]].to_csv(val_annotations_fp, sep='\\t', header=False, index=False)\n",
    "    \n",
    "    # actually run the script and read the results back in\n",
    "    prediction_fp = os.path.join(SANDBOX_DIR, 'seurat_predictions.txt')\n",
    "    subprocess.check_output(('Rscript', SEURAT_SCRIPT, train_counts_fp, train_annotations_fp,\n",
    "                        val_counts_fp, val_annotations_fp, prediction_fp))\n",
    "    \n",
    "    # format the predictions dataframe\n",
    "    df = pd.read_csv(prediction_fp, sep='\\t')\n",
    "    df.index = [x.replace('.', '-') for x in df.index]\n",
    "    df = pd.merge(df, val.obs, left_index=True, right_index=True)\n",
    "    try:\n",
    "        df = df[['cell_type', 'predicted.id', 'prediction.score.max']]        \n",
    "        df.index.name = 'cell_id'\n",
    "        df.columns = ['groundtruth', 'predictions', 'probability']\n",
    "        return df\n",
    "    except KeyError as e:\n",
    "        print(f'key error', e)\n",
    "        return pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scRNAseq brca (2600, 27131) (11253, 27131)\n",
      "scRNAseq cesc (1941, 22928) (8449, 22928)\n",
      "scRNAseq hnscc (2200, 26929) (10288, 26929)\n",
      "scRNAseq melanoma (2000, 23452) (6735, 23452)\n",
      "key error \"['predicted.id', 'prediction.score.max'] not in index\"\n",
      "scRNAseq pbmc (940, 32738) (1698, 32738)\n",
      "scRNAseq pdac (3296, 28756) (15435, 28756)\n",
      "snATACseq brca (2064, 19891) (9028, 19891)\n",
      "key error \"['predicted.id', 'prediction.score.max'] not in index\"\n",
      "snATACseq gbm (1316, 19891) (5650, 19891)\n",
      "key error \"['predicted.id', 'prediction.score.max'] not in index\"\n",
      "snRNAseq brca (2455, 29175) (9490, 29175)\n"
     ]
    }
   ],
   "source": [
    "SEURAT_SCRIPT = '/home/estorrs/pollock/benchmarking/tools/run_seurat_workflow.R'\n",
    "run_workflow_for_datasets(adata_map, run_seurat_transfer, 'seurat_transfer', RESULTS_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "###### testing stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# train, val = adata_map['scRNAseq']['pbmc']['train'].copy(), adata_map['scRNAseq']['pbmc']['val'].copy()\n",
    "train, val = adata_map['scRNAseq']['cesc']['train'].copy(), adata_map['scRNAseq']['cesc']['val'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pow(2, 14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_counts_fp, val_counts_fp = (os.path.join(SANDBOX_DIR, 'train_counts.txt'),\n",
    "                                    os.path.join(SANDBOX_DIR, 'val_counts.txt'))\n",
    "train_annotations_fp, val_annotations_fp = (os.path.join(SANDBOX_DIR, 'train_annotations.txt'),\n",
    "                                            os.path.join(SANDBOX_DIR, 'val_annotations.txt'))\n",
    "\n",
    "X = train.X.toarray() if 'sparse' in str(type(train.X)) else train.X\n",
    "train_counts = pd.DataFrame(data=X.transpose().astype(np.int32), index=train.var.index,\n",
    "                            columns=train.obs.index)\n",
    "train_counts.index.name = ''\n",
    "train_counts.columns = [c.replace('_', '-') for c in train_counts.columns]\n",
    "cap = pow(2, 14)\n",
    "train_counts.values[train_counts.values>cap] = cap\n",
    "train_counts.to_csv(train_counts_fp, sep='\\t', header=True, index=True)\n",
    "X = val.X.toarray() if 'sparse' in str(type(val.X)) else val.X\n",
    "val_counts = pd.DataFrame(data=X.transpose().astype(np.int32), index=val.var.index,\n",
    "                            columns=val.obs.index)\n",
    "val_counts.index.name = ''\n",
    "val_counts = val_counts.iloc[:, :1000]\n",
    "val_counts.values[val_counts.values>cap] = cap\n",
    "val_counts.to_csv(val_counts_fp, sep='\\t', header=True, index=True)\n",
    "\n",
    "train.obs[[CELL_TYPE_KEY]].to_csv(train_annotations_fp, sep='\\t', header=False, index=False)\n",
    "val.obs[[CELL_TYPE_KEY]].to_csv(val_annotations_fp, sep='\\t', header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# t = pd.read_csv(val_counts_fp, sep='\\t')\n",
    "# t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "type(train_counts.values), type(train_counts.values[0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "vals = sorted(set(train_counts.values.flatten()))\n",
    "vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "vals[:10], vals[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_counts.values[train_counts.values>1000] = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "np.where(train_counts>1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "prediction_fp = os.path.join(SANDBOX_DIR, 'seurat_predictions.txt')\n",
    "subprocess.check_output(('Rscript', SEURAT_SCRIPT, train_counts_fp, train_annotations_fp,\n",
    "                        val_counts_fp, val_annotations_fp, prediction_fp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(prediction_fp, sep='\\t')\n",
    "df.index = [x.replace('.', '-') for x in df.index]\n",
    "df = pd.merge(df, val.obs, left_index=True, right_index=True)\n",
    "\n",
    "df = df[['cell_type', 'predicted.id', 'prediction.score.max']]\n",
    "df.index.name = 'cell_id'\n",
    "df.columns = ['groundtruth', 'predictions', 'probability']\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "val.obs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### SingleCellNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install git+https://github.com/pcahan1/PySingleCellNet/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pySingleCellNet as pySCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_SingleCellNet(train, val, cell_type_key):\n",
    "    # save the input data for the seurat script\n",
    "    cgenesA, xpairs, tspRF = pySCN.scn_train(train,\n",
    "            nTopGenes=100, nRand=100, nTrees=1000, nTopGenePairs=100,\n",
    "            dLevel=cell_type_key, stratify=True, limitToHVG=True, )\n",
    "    predictions = pySCN.scn_classify(val, cgenesA, xpairs, tspRF, nrand = 0)\n",
    "    \n",
    "    df = pd.merge(predictions.obs[['SCN_class']], val.obs, left_index=True, right_index=True)\n",
    "\n",
    "    df = df[['cell_type', 'SCN_class']]\n",
    "    df.index.name = 'cell_id'\n",
    "    df.columns = ['groundtruth', 'predictions']\n",
    "    df['probability'] = [np.nan] * df.shape[0]\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_workflow_for_datasets(adata_map, run_SingleCellNet, 'SingleCellNet', RESULTS_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "###### testing stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train, val = adata_map['scRNAseq']['pbmc']['train'].copy(), adata_map['scRNAseq']['pbmc']['val'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cgenesA, xpairs, tspRF = pySCN.scn_train(train,\n",
    "            nTopGenes = 100, nRand = 100, nTrees = 1000 ,nTopGenePairs = 100,\n",
    "            dLevel = \"cell_type\", stratify=True, limitToHVG=True, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "predictions = pySCN.scn_classify(val, cgenesA, xpairs, tspRF, nrand = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "predictions.obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df = pd.merge(predictions.obs[['SCN_class']], val.obs, left_index=True, right_index=True)\n",
    "\n",
    "df = df[['cell_type', 'SCN_class']]\n",
    "df.index.name = 'cell_id'\n",
    "df.columns = ['groundtruth', 'predictions']\n",
    "df['probability'] = [np.nan] * df.shape[0]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### pollock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### testing stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
